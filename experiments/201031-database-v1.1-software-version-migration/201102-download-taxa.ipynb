{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 201102 Download taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "from tqdm import tqdm\n",
    "from Bio import Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = 'mjlumpe@gmail.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = Path('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path('../../data/intermediate/201031-database-v1.1-software-version-migration/201102-download-taxa/')\n",
    "outdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def throttle(min_interval, max_attempts=5):\n",
    "    \"\"\"Decorator to throttle API request function.\"\"\"\n",
    "    \n",
    "    def decorator(f):\n",
    "        last_request = datetime.now() - timedelta(seconds=min_interval)\n",
    "        \n",
    "        def rate_limited(*args, **kwargs):\n",
    "            nonlocal last_request\n",
    "            \n",
    "            last_exc = None\n",
    "            \n",
    "            for i in range(max_attempts):\n",
    "                \n",
    "                # Sleep until min interval reached if necessary\n",
    "                interval = (datetime.now() - last_request).total_seconds()\n",
    "                if interval < min_interval:\n",
    "                    sleep(min_interval - interval)\n",
    "                    \n",
    "                # Attempt request, catching HTTPError's\n",
    "                try:\n",
    "                    return f(*args, **kwargs)\n",
    "                \n",
    "                except HTTPError as e:\n",
    "                    last_exc = e\n",
    "                    \n",
    "                finally:\n",
    "                    # Update last request time whether we succeeded or not\n",
    "                    last_request = datetime.now()\n",
    "                    \n",
    "            # Reached max # of attempts\n",
    "            raise RuntimeError('Exceeded %d attempts' % max_attempts) from last_exc\n",
    "                \n",
    "        return rate_limited\n",
    "    \n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(datestr):\n",
    "    return datetime.strptime(datestr, '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "def taxon_xml_to_json(txml):\n",
    "    \"\"\"Convert parsed taxon XML element to JSON-like format that's much easier to work with.\"\"\"\n",
    "    assert txml.tag == 'Taxon'\n",
    "    \n",
    "    return dict(\n",
    "        taxid=int(txml.findtext('TaxId')),\n",
    "        parent_taxid=int(txml.findtext('ParentTaxId')),\n",
    "        scientific_name=txml.findtext('ScientificName'),\n",
    "        rank=txml.findtext('Rank'),\n",
    "        division=txml.findtext('Division'),\n",
    "        create_date=parse_date(txml.findtext('CreateDate')),\n",
    "        update_date=parse_date(txml.findtext('UpdateDate')),\n",
    "        pub_date=parse_date(txml.findtext('PubDate')),\n",
    "        aka_taxids=[int(e.text) for e in txml.findall('./AkaTaxIds/TaxId')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efetch_taxa(taxids):\n",
    "    taxids = list(taxids)\n",
    "    resp = Entrez.efetch(db='taxonomy', id=taxids)\n",
    "    doc = ET.parse(resp)\n",
    "    root = doc.getroot()\n",
    "    assert root.tag == 'TaxaSet'\n",
    "    \n",
    "    taxa = dict()\n",
    "    \n",
    "    for txml in root.findall('./Taxon'):\n",
    "        tdata = taxon_xml_to_json(txml)\n",
    "        \n",
    "        # Get primary or alternate taxon ID that was passed to the function\n",
    "        taxid = tdata['taxid']\n",
    "        if taxid not in taxids:\n",
    "            for id2 in tdata['aka_taxids']:\n",
    "                if id2 in taxids:\n",
    "                    taxid = id2\n",
    "                    break\n",
    "            else:\n",
    "                raise RuntimeError('Could not determine requested taxid')\n",
    "                \n",
    "        taxa[taxid] = (txml, tdata)\n",
    "    \n",
    "    return taxa\n",
    "\n",
    "efetch_taxa_throttled = throttle(1/3)(efetch_taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download taxonomy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmpdir / 'genome_taxids.json') as f:\n",
    "    genome_taxids = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_dir = tmpdir / 'taxa'\n",
    "tax_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_to_download = set(genome_taxids)\n",
    "taxon_data = dict()\n",
    "aka_taxids = dict()  # Map alternate taxon IDs to their canonical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_parenttaxids = [0]  # Stop climbing lineage at these IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_taxon(taxid, txml, tdata=None):\n",
    "    \"\"\"Add downloaded taxonomy data to our list, add parent to download list if needed.\"\"\"\n",
    "    if tdata is None:\n",
    "        tdata = taxon_xml_to_json(txml)\n",
    "    true_taxid = tdata['taxid']\n",
    "    \n",
    "    # Check we have the expected ID\n",
    "    assert true_taxid == taxid or taxid in tdata['aka_taxids']\n",
    "    \n",
    "    taxon_data[true_taxid] = tdata\n",
    "    taxa_to_download.remove(taxid)\n",
    "    \n",
    "    # Record alternate ids\n",
    "    for id2 in tdata['aka_taxids']:\n",
    "        assert id2 not in aka_taxids\n",
    "        aka_taxids[id2] = true_taxid\n",
    "    \n",
    "    # Add parent to download list if we don't have it yet\n",
    "    parentid = tdata['parent_taxid']\n",
    "    if parentid not in ignore_parenttaxids and parentid not in taxon_data:\n",
    "        taxa_to_download.add(parentid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22474/22474 [00:03<00:00, 7214.92it/s]\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 100\n",
    "\n",
    "with tqdm(total=len(taxa_to_download) + len(taxon_data), initial=len(taxon_data)) as pbar:\n",
    "    while taxa_to_download:\n",
    "        \n",
    "        # Find next chunk of IDs to download\n",
    "        next_chunk = []\n",
    "        \n",
    "        for taxid in list(taxa_to_download):\n",
    "            dst = tax_dir / ('%d.xml' % taxid)\n",
    "            \n",
    "            if dst.is_file():\n",
    "                with dst.open() as f:\n",
    "                    txml = ET.parse(f).getroot()\n",
    "                record_taxon(taxid, txml)\n",
    "                    \n",
    "            else:\n",
    "                next_chunk.append(taxid)\n",
    "                if len(next_chunk) >= chunk_size:\n",
    "                    break\n",
    "                    \n",
    "        if next_chunk:\n",
    "\n",
    "            # Fetch\n",
    "            chunk_taxa = efetch_taxa_throttled(next_chunk)\n",
    "\n",
    "            # Add results\n",
    "            for taxid, (txml, tdata) in chunk_taxa.items():\n",
    "                record_taxon(taxid, txml, tdata)\n",
    "\n",
    "                # Write to file\n",
    "                dst = tax_dir / ('%d.xml' % taxid)\n",
    "                assert not dst.is_file()\n",
    "                with dst.open('wb') as f:\n",
    "                    f.write(ET.tostring(txml))\n",
    "                \n",
    "        # Update progress bar\n",
    "        total = len(taxon_data) + len(taxa_to_download)\n",
    "        if pbar.total != total:\n",
    "            pbar.total = total\n",
    "        pbar.n = len(taxon_data)\n",
    "        pbar.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check we have one entry per set of aliases\n",
    "for (id2, taxid) in aka_taxids.items():\n",
    "    assert id2 not in taxon_data \n",
    "    assert taxid in taxon_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaxonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        return super().default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir / 'taxa.json', 'w') as f:\n",
    "    json.dump(list(taxon_data.values()), f, cls=TaxonEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir / 'aka_taxids.json', 'w') as f:\n",
    "    json.dump(aka_taxids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_true_taxids = list({aka_taxids.get(tid, tid) for tid in genome_taxids})\n",
    "\n",
    "with open(tmpdir / 'genome_true_taxids.json', 'w') as f:\n",
    "    json.dump(genome_true_taxids, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIDAS 2",
   "language": "python",
   "name": "midas2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
